import gradio as gr
import os
import time
from PIL import Image, ImageDraw
import numpy as np

# Import c√°c module t·ª´ b·ªô l√µi AI
from modules.detection import TextDetector
from modules.ocr import UniversalOCR
from modules.translator import LocalLLMTranslator
from modules.inpainting import Inpainter

# --- BI·∫æN TO√ÄN C·ª§C ƒê·ªÇ L∆ØU MODEL (TR√ÅNH RELOAD L·∫†I NHI·ªÄU L·∫¶N) ---
MODELS = {
    "detector": None,
    "ocr": None,
    "translator": None,
    "inpainter": None,
    "current_lang": None
}

def load_ai_models(lang_code):
    """H√†m kh·ªüi t·∫°o model, ch·ªâ ch·∫°y 1 l·∫ßn ho·∫∑c khi ƒë·ªïi ng√¥n ng·ªØ OCR"""
    global MODELS
    status_msg = ""
    
    # 1. Detection
    if MODELS["detector"] is None:
        status_msg += "‚è≥ ƒêang t·∫£i Text Detector...\n"
        MODELS["detector"] = TextDetector()
        
    # 2. OCR (Reload n·∫øu ƒë·ªïi ng√¥n ng·ªØ)
    ocr_lang_map = {'jp': 'japan', 'en': 'en', 'cn': 'ch', 'th': 'th', 'vi': 'vi'}
    target_ocr_lang = ocr_lang_map.get(lang_code, 'en')
    
    if MODELS["ocr"] is None or MODELS["current_lang"] != lang_code:
        status_msg += f"‚è≥ ƒêang t·∫£i OCR ({target_ocr_lang})...\n"
        # X√≥a model c≈© kh·ªèi VRAM n·∫øu c·∫ßn thi·∫øt (·ªü ƒë√¢y t·∫°m b·ªè qua ƒë·ªÉ ƒë∆°n gi·∫£n)
        MODELS["ocr"] = UniversalOCR(lang=target_ocr_lang)
        MODELS["current_lang"] = lang_code

    # 3. Translator (N·∫∑ng nh·∫•t)
    if MODELS["translator"] is None:
        status_msg += "‚è≥ ƒêang t·∫£i Qwen LLM (Translator)...\n"
        MODELS["translator"] = LocalLLMTranslator()

    # 4. Inpainter
    if MODELS["inpainter"] is None:
        status_msg += "‚è≥ ƒêang t·∫£i LaMa (Inpainter)...\n"
        MODELS["inpainter"] = Inpainter()
        
    return status_msg + "‚úÖ T·∫•t c·∫£ Model ƒë√£ s·∫µn s√†ng!"

def process_manga(image_path, lang_code, progress=gr.Progress()):
    """H√†m x·ª≠ l√Ω ch√≠nh g·ªçi t·ª´ UI"""
    if image_path is None:
        return None, None, "Vui l√≤ng upload ·∫£nh!"

    # Load models n·∫øu ch∆∞a c√≥
    progress(0.1, desc="Ki·ªÉm tra Model...")
    load_log = load_ai_models(lang_code)
    
    try:
        # 1. Detect
        progress(0.3, desc="ƒêang t√¨m khung tho·∫°i...")
        detector = MODELS["detector"]
        bboxes = detector.detect(image_path)
        
        # V·∫Ω box l√™n ·∫£nh g·ªëc ƒë·ªÉ preview
        original_img = Image.open(image_path).convert("RGB")
        preview_img = original_img.copy()
        draw = ImageDraw.Draw(preview_img)
        for box in bboxes:
            draw.rectangle(box, outline="red", width=3)
        
        if len(bboxes) == 0:
            return preview_img, original_img, "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khung tho·∫°i n√†o!"

        # 2. OCR
        progress(0.5, desc="ƒêang ƒë·ªçc ch·ªØ...")
        ocr_engine = MODELS["ocr"]
        raw_texts = []
        for box in bboxes:
            text = ocr_engine.run(original_img, box)
            if len(text.strip()) == 0: text = "..."
            raw_texts.append(text)

        # 3. Translate
        progress(0.7, desc="AI ƒëang d·ªãch...")
        translator = MODELS["translator"]
        translated_texts = translator.translate(raw_texts, source_lang=lang_code)

        # 4. Inpaint
        progress(0.9, desc="ƒêang x√≥a ch·ªØ...")
        inpainter = MODELS["inpainter"]
        clean_image = inpainter.remove_text(image_path, bboxes)

        # Format k·∫øt qu·∫£ text
        result_text = ""
        for i, (raw, trans) in enumerate(zip(raw_texts, translated_texts)):
            result_text += f"[Box {i+1}]\nORIGIN: {raw}\nVIET: {trans}\n\n"

        return preview_img, clean_image, result_text

    except Exception as e:
        return None, None, f"‚ùå L·ªói x·ª≠ l√Ω: {str(e)}"

# --- GIAO DI·ªÜN GRADIO ---
with gr.Blocks(title="AI Manga Translator Pro", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ü§ñ AI Manga Translator Pro")
    gr.Markdown("C√¥ng c·ª• d·ªãch truy·ªán tranh t·ª± ƒë·ªông s·ª≠ d·ª•ng: YOLO (Detect) + PaddleOCR + Qwen-7B (D·ªãch) + LaMa (X√≥a ch·ªØ).")
    
    with gr.Row():
        with gr.Column(scale=1):
            # Input
            input_img = gr.Image(type="filepath", label="Upload trang truy·ªán", height=600)
            lang_dropdown = gr.Dropdown(
                choices=["jp", "en", "cn", "th", "vi"], 
                value="jp", 
                label="Ng√¥n ng·ªØ g·ªëc"
            )
            btn_run = gr.Button("üöÄ D·ªäCH NGAY", variant="primary")
            
        with gr.Column(scale=2):
            # Output
            with gr.Tab("K·∫øt qu·∫£ h√¨nh ·∫£nh"):
                with gr.Row():
                    out_detect = gr.Image(label="Ph√°t hi·ªán khung tho·∫°i", type="pil")
                    out_clean = gr.Image(label="·∫¢nh ƒë√£ x√≥a ch·ªØ (Clean)", type="pil")
            
            with gr.Tab("B·∫£n d·ªãch Text"):
                out_text = gr.Textbox(label="N·ªôi dung d·ªãch (Song ng·ªØ)", lines=20, show_copy_button=True)

    # S·ª± ki·ªán click n√∫t
    btn_run.click(
        fn=process_manga,
        inputs=[input_img, lang_dropdown],
        outputs=[out_detect, out_clean, out_text]
    )

if __name__ == "__main__":
    # share=True ƒë·ªÉ t·∫°o link public ch·∫°y tr√™n Colab/Kaggle
    demo.launch(share=True, debug=True)
